{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtcBjMq7YV3f"
      },
      "source": [
        "# Homework 2 - Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn-cOk1iZTtR"
      },
      "source": [
        "In this part of the homework we are going to work with Recurrent Neural Networks, in particular GRU. One of the greatest things that Recurrent Neural Networks can do when working with sequences is retaining data from several timesteps in the past. We are going to explore that property by constructing an 'echo' Recurrent Neural Network.\n",
        "\n",
        "The goal here is to make a model that given a sequence of letters or digits will output that same sequence, but with a certain delay. Let's say the input is a string 'abacaba', we want the model to not output anything for 3 steps (delay length), and then output the original string step by step, except the last 3 characters. So, target output is then 'XXXabac', where 'X' is empty output.\n",
        "\n",
        "This is similar to [this notebook](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb) (which you should refer to when doing this assignment), except we're working not with a binary string, but with a sequence of integers between 0 and some N. In our case N is 26, which is the number of letters in the alphabet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npLlE973as6x"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Let's implement the dataset. In our case, the data is basically infinite, as we can always generate more examples on the fly, so don't need to load anything from disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "mkEEMyvzIMRx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "import torch\n",
        "\n",
        "# Max value of the generated integer. 26 is chosen becuase it's\n",
        "# the number of letters in English alphabet.\n",
        "N = 26\n",
        "\n",
        "def idx_to_onehot(x, k=N+1):\n",
        "  ones = torch.sparse.torch.eye(k).to(x.device)\n",
        "  \"\"\" Converts the generated integers to one-hot vectors \"\"\"\n",
        "  shape = x.shape\n",
        "  res = ones.index_select(0, x.view(-1).type(torch.int64))\n",
        "  return res.view(*shape, res.shape[-1])\n",
        "\n",
        "class EchoDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "  def __init__(self, delay=3, seq_length=15, size=1000):\n",
        "    self.delay = delay\n",
        "    self.seq_length = seq_length\n",
        "    self.size = size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __iter__(self):\n",
        "    \"\"\" Iterable dataset doesn't have to implement __getitem__.\n",
        "        Instead, we only need to implement __iter__ to return\n",
        "        an iterator (or generator).\n",
        "    \"\"\"\n",
        "    for _ in range(self.size):\n",
        "      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n",
        "      result = torch.cat((torch.zeros(self.delay), seq[:self.seq_length - self.delay])).type(torch.int64)\n",
        "      yield seq, result\n",
        "\n",
        "DELAY = 4\n",
        "DATASET_SIZE = 200000\n",
        "ds = EchoDataset(delay=DELAY, size=DATASET_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrZqYURcKSl"
      },
      "source": [
        "## Model\n",
        "\n",
        "Now, we want to implement the model. For our purposes, we want to use GRU. The architecture consists of GRU and a decoder. Decoder is responsible for decoding the GRU hidden state to yield a predicting for the next output. The parts you are responsible for filling with your code are marked with `TODO`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "nigN_o4Mb9Nx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GRUMemory(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size):\n",
        "    super().__init__()\n",
        "    #TODO: initialize your submodules\n",
        "    self.hidden_size = hidden_size\n",
        "    self.gru = nn.GRU(input_size = 27, hidden_size=hidden_size, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, 27)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # inputs: x - input tensor of shape (batch_size, seq_length, N+1)\n",
        "    # returns:\n",
        "    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n",
        "    # TODO implement forward pass\n",
        "    gru_out, _ = self.gru(x) \n",
        "    return self.linear(gru_out) \n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test_run(self, s):\n",
        "    # This function accepts one string s containing lowercase characters a-z.\n",
        "    # You need to map those characters to one-hot encodings of shape (len(s), N + 1),\n",
        "    # then feed the on-hot encodings into your network,\n",
        "    # then get the output from your network,\n",
        "    # then convert the output back to a string of the same length, with 0 mapped to ' ',\n",
        "    # and 1-26 mapped to a-z.\n",
        "\n",
        "    # TODO\n",
        "    char_to_idx = {char: idx + 1 for idx, char in enumerate('abcdefghijklmnopqrstuvwxyz')}\n",
        "    char_to_idx[' '] = 0\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "    indices = torch.tensor([char_to_idx[char] for char in s], dtype=torch.long)\n",
        "     # Move inputs to the correct device (the same device as the model)\n",
        "    device = next(self.parameters()).device\n",
        "    indices = indices.to(device)\n",
        "    \n",
        "    one_hot_vector = idx_to_onehot(indices)\n",
        "\n",
        "    one_hot_vector = one_hot_vector.unsqueeze(0)  # (1, seq_length, N+1)\n",
        "    output = self.forward(one_hot_vector)\n",
        "    output_idx = torch.argmax(output, dim=-1).squeeze(0) # (seq_length,)\n",
        "    return ''.join([idx_to_char[idx.item()] for idx in output_idx])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9whwmVu9OIx"
      },
      "source": [
        "## Training\n",
        "Below you need to implement the training of the model. We give you more freedom as for the implementation. The two limitations are that it has to execute within 10 minutes, and that error rate should be below 1%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "lUZkeRnVTNzG"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "  model.eval()\n",
        "  \"\"\"\n",
        "  This is the test function that runs 100 different strings through your model,\n",
        "  and checks the error rate.\n",
        "  \"\"\"\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for i in range(500):\n",
        "    s = ''.join([random.choice(string.ascii_lowercase) for i in range(random.randint(15, 25))])\n",
        "    result = model.test_run(s)\n",
        "    for c1, c2 in zip(s[:-DELAY], result[DELAY:]):\n",
        "      correct += int(c1 == c2)\n",
        "    total += len(s) - DELAY\n",
        "\n",
        "  return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "9lV9BscxCCAI"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b76772ddf8f84252beb721e62574bf51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/2:   0%|          | 0/6250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[119], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m GRUMemory(HIDDEN_SIZE)\n\u001b[0;32m     45\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m---> 46\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     49\u001b[0m duration \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
            "Cell \u001b[1;32mIn[119], line 24\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m     21\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[0;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m idx_to_onehot(inputs)\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[0;32m     26\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# type for CrossEntropyLoss\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:33\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter))\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[116], line 34\u001b[0m, in \u001b[0;36mEchoDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize):\n\u001b[0;32m     33\u001b[0m   seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length)], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m---> 34\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m seq, result\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "from torch import nn, optim\n",
        "start_time = time.time()\n",
        "\n",
        "HIDDEN_SIZE=64 # TODO\n",
        "BATCH_SIZE=32 #TODO\n",
        "\n",
        "num_epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train_model(model, dataloader):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    \n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "        \n",
        "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False) as pbar:\n",
        "      for i, (inputs, targets) in enumerate(pbar):\n",
        "        inputs = idx_to_onehot(inputs).to(device)  \n",
        "        targets = targets.long().to(device)  # type for CrossEntropyLoss\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "                \n",
        "        outputs = outputs.view(-1, N+1) \n",
        "        targets = targets.view(-1)  \n",
        "                \n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update running loss here\n",
        "        running_loss = loss.item()\n",
        "        epoch_loss += running_loss\n",
        "        pbar.set_postfix({'epoch_loss': epoch_loss / (i + 1)})\n",
        "        \n",
        "\n",
        "model = GRUMemory(HIDDEN_SIZE)\n",
        "dataloader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE)\n",
        "train_model(model, dataloader)\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "accuracy = test_model(model)\n",
        "print(accuracy)\n",
        "assert duration < 600, 'execution took f{duration:.2f} seconds, which longer than 10 mins'\n",
        "assert accuracy > 0.99, f'accuracy is too low, got {accuracy}, need 0.99'\n",
        "print('tests passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB0EVNBtDhpN"
      },
      "source": [
        "## Variable delay model\n",
        "\n",
        "Now, to make this more complicated, we want to have varialbe delay. So, now, the goal is to transform a sequence of pairs (character, delay) into a character sequence with given delay. Delay stays constant within one sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i_iwX_AEOCH"
      },
      "source": [
        "### Dataset\n",
        "As before, we first implement the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "E4G5b8kuEUEd"
      },
      "outputs": [],
      "source": [
        "class VariableDelayEchoDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "  def __init__(self, max_delay=8, seq_length=20, size=1000):\n",
        "    self.max_delay = max_delay\n",
        "    self.seq_length = seq_length\n",
        "    self.size = size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __iter__(self):\n",
        "    for _ in range(self.size):\n",
        "      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n",
        "      delay = random.randint(0, self.max_delay)\n",
        "      result = torch.cat((torch.zeros(delay), seq[:self.seq_length - delay])).type(torch.int64)\n",
        "      yield seq, delay, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTRVOND3HEJZ"
      },
      "source": [
        "### Model\n",
        "\n",
        "And the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IYolFIB8Hg0U"
      },
      "outputs": [],
      "source": [
        "class VariableDelayGRUMemory(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, max_delay):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.max_delay = max_delay\n",
        "    self.gru = nn.GRU(input_size=N+1, hidden_size=hidden_size, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, N+1)\n",
        "    self.delay_embeds = nn.Embedding(max_delay+1, hidden_size) # this would be concatenated with the output\n",
        "\n",
        "  def forward(self, x, delays):\n",
        "    # inputs:\n",
        "    # x - tensor of shape (batch size, seq length, N + 1)\n",
        "    # delays - tensor of shape (batch size)\n",
        "    # returns:\n",
        "    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n",
        "\n",
        "    # TODO\n",
        "    gru_out, _ = self.gru(x)\n",
        "    delay_embeds = self.delay_embeds(delays)  # (batch_size, hidden_size)\n",
        "    delay_embeds = delay_embeds.unsqueeze(1).expand(-1, x.size(1), -1)  # need (batch_size, seq_length, hidden_size)\n",
        "    output = gru_out + delay_embeds\n",
        "    return self.linear(output)\n",
        "  \n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test_run(self, s, delay):\n",
        "    # This function accepts one string s containing lowercase characters a-z,\n",
        "    # and an int delay - the desired output delay.\n",
        "    # You need to map those characters to one-hot encodings,\n",
        "    # then feed the one-hot encodings into your network,\n",
        "    # then get the output from your network,\n",
        "    # then convert the output back to a string of the same length, with 0 mapped to ' ',\n",
        "    # and 1-26 mapped to a-z.\n",
        "    char_to_idx = {char: idx + 1 for idx, char in enumerate('abcdefghijklmnopqrstuvwxyz')}\n",
        "    char_to_idx[' '] = 0\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "    indices = torch.tensor([char_to_idx[char] for char in s], dtype=torch.long)\n",
        "     # Move inputs to the correct device (the same device as the model)\n",
        "    device = next(self.parameters()).device\n",
        "    one_hot_vector = idx_to_onehot(indices).float().unsqueeze(0).to(device)  # (1, seq_length, N+1)    \n",
        "    delay_tensor = torch.tensor([delay], dtype=torch.long, device=device)\n",
        "    output = self.forward(one_hot_vector, delay_tensor)\n",
        "    output_idx = torch.argmax(output, dim=-1).squeeze(0)\n",
        "\n",
        "    return ''.join([idx_to_char[idx.item()] for idx in output_idx])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Mly06pPw-6B1"
      },
      "outputs": [],
      "source": [
        "def test_variable_delay_model(model, max_delay=12):\n",
        "  \"\"\"\n",
        "  This is the test function that runs 100 different strings through your model,\n",
        "  and checks the error rate.\n",
        "  \"\"\"\n",
        "  delay = random.randint(0, max_delay)\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for i in range(1000):\n",
        "    s = ''.join([random.choice(string.ascii_lowercase) for i in range(random.randint(15, 25))])\n",
        "    result = model.test_run(s, delay)\n",
        "    for c1, c2 in zip(s[:-delay], result[delay:]):\n",
        "      correct += int(c1 == c2)\n",
        "    total += len(s) - delay\n",
        "\n",
        "  return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riu3qHWgKjsx"
      },
      "source": [
        "### Train\n",
        "\n",
        "As before, you're free to do what you want, as long as training finishes within 10 minutes and accuracy is above 0.99 for delays between 0 and 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "yUKJQWHguLAQ"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a98f8f89efa4e24afab9d9ecbd26ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/4:   0%|          | 0/9375 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[115], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m ds \u001b[38;5;241m=\u001b[39m VariableDelayEchoDataset(max_delay\u001b[38;5;241m=\u001b[39mMAX_DELAY, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600000\u001b[39m, seq_length\u001b[38;5;241m=\u001b[39mSEQ_LENGTH)\n\u001b[0;32m     50\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mtrain_variable_delay_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m end_time \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecuting took longer than 10 mins\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "Cell \u001b[1;32mIn[115], line 44\u001b[0m, in \u001b[0;36mtrain_variable_delay_model\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m     42\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     43\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m running_loss\n\u001b[1;32m---> 44\u001b[0m \u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1432\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[1;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m   1430\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[1;32m-> 1432\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1348\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m-> 1348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:170\u001b[0m, in \u001b[0;36mtqdm_notebook.display\u001b[1;34m(self, msg, pos, close, bar_style, check_delay)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# never clear the bar (signal: msg='')\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m right:\n\u001b[1;32m--> 170\u001b[0m         \u001b[43mrtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m \u001b[38;5;241m=\u001b[39m right\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Change bar style\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bar_style:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Hack-ish way to avoid the danger bar_style being overridden by\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# success because the bar gets closed after the error...\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\traitlets.py:745\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m trait is read-only.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\traitlets.py:734\u001b[0m, in \u001b[0;36mTraitType.set\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    730\u001b[0m     silent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# we explicitly compare silent to True just in case the equality\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# comparison above returns something other than True/False\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m     \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_notify_trait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\traitlets.py:1516\u001b[0m, in \u001b[0;36mHasTraits._notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_notify_trait\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, old_value, new_value):\n\u001b[1;32m-> 1516\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotify_change\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m            \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py:700\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;66;03m# Make sure this isn't information that the front-end just sent us.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_send_property(name, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)):\n\u001b[0;32m    699\u001b[0m         \u001b[38;5;66;03m# Send new state to front-end\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mnotify_change(change)\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py:586\u001b[0m, in \u001b[0;36mWidget.send_state\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    584\u001b[0m state, buffer_paths, buffers \u001b[38;5;241m=\u001b[39m _remove_buffers(state)\n\u001b[0;32m    585\u001b[0m msg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer_paths\u001b[39m\u001b[38;5;124m'\u001b[39m: buffer_paths}\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffers\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py:825\u001b[0m, in \u001b[0;36mWidget._send\u001b[1;34m(self, msg, buffers)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a message to the model in the front-end.\"\"\"\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffers\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\comm\\base_comm.py:113\u001b[0m, in \u001b[0;36mBaseComm.send\u001b[1;34m(self, data, metadata, buffers)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a message to the frontend-side version of this comm\"\"\"\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_msg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomm_msg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\comm\\comm.py:36\u001b[0m, in \u001b[0;36mBaseComm.publish_msg\u001b[1;34m(self, msg_type, data, metadata, buffers, **keys)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m Kernel\u001b[38;5;241m.\u001b[39minstance()\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miopub_socket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_clean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mident\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jupyter_client\\session.py:861\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stream:\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# use dummy tracker, which will be done immediately\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     tracker \u001b[38;5;241m=\u001b[39m DONE\n\u001b[1;32m--> 861\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_multipart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m    864\u001b[0m     pprint\u001b[38;5;241m.\u001b[39mpprint(msg)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\iostream.py:346\u001b[0m, in \u001b[0;36mBackgroundSocket.send_multipart\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Schedule send in IO thread\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_multipart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\iostream.py:276\u001b[0m, in \u001b[0;36mIOPubThread.send_multipart\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_multipart\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"send_multipart schedules actual zmq send in my thread.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    If my thread isn't running (e.g. forked process), send immediately.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_really_send\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\gbert\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "MAX_DELAY = 12\n",
        "SEQ_LENGTH = 20\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "\n",
        "HIDDEN_SIZE=512 # TODO\n",
        "BATCH_SIZE=64 #TODO\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 4\n",
        "\n",
        "def train_variable_delay_model(model, dataloader):\n",
        "  # TODO: implement training\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "        \n",
        "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False) as pbar:\n",
        "      for i, (inputs, delays, targets) in enumerate(pbar):\n",
        "        inputs = idx_to_onehot(inputs).to(device)  \n",
        "        targets = targets.long().to(device)  # type for CrossEntropyLoss\n",
        "        delays = delays.long().to(device)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, delays)\n",
        "                \n",
        "        outputs = outputs.view(-1, N+1) \n",
        "        targets = targets.view(-1)  # flatten\n",
        "                \n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update running loss here\n",
        "        running_loss = loss.item()\n",
        "        epoch_loss += running_loss\n",
        "        pbar.set_postfix({'epoch_loss': epoch_loss / (i + 1)})\n",
        "        \n",
        "    \n",
        "\n",
        "model = VariableDelayGRUMemory(hidden_size=HIDDEN_SIZE, max_delay=MAX_DELAY)\n",
        "ds = VariableDelayEchoDataset(max_delay=MAX_DELAY, size=600000, seq_length=SEQ_LENGTH)\n",
        "dataloader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE)\n",
        "train_variable_delay_model(model, dataloader)\n",
        "\n",
        "end_time = time.time()\n",
        "assert end_time - start_time < 600, 'executing took longer than 10 mins'\n",
        "accuracy = test_variable_delay_model(model, max_delay=MAX_DELAY)\n",
        "print(accuracy)\n",
        "assert accuracy > 0.95, 'accuracy is too low'\n",
        "print('tests passed')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
