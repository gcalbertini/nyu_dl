%This is my super simple Real Analysis Homework template

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,bm}
\usepackage{minted}
\usepackage[]{tcolorbox}
\usepackage[]{amsthm} %lets us use \begin{proof}
\usepackage[]{amssymb} %gives us the character \varnothing

\title{Homework 1}
\author{Guilherme Albertini}
\date\today
%This information doesn't actually show up on your document unless you use the maketitle command below

\begin{document}
\maketitle %This command prints the title based on information entered above

%Section and subsection automatically number unless you put the asterisk next to them.
\section*{Theory}
Let $Linear_1 \rightarrow f \rightarrow  Linear_2 \rightarrow g $ be a be a
two-layer neural net architecture whereby $Linear_i(x) =
  \bm{W}^{(i)}\bm{x}+\bm{b}^{(i)}$ is the $i^{th}$ affine transformation and
$f,
  g$ are element-wise nonlinear activation functions (else must use transposes and/or Hadamard products). When an input $\bm{x}\in
  \mathbb{R}^n$ is fed into the network, $\bm{\hat{y}} \in \mathbb{R}^K$ is
obtained as output.
%Basically, you type whatever text you want and use the $ sign to enter "math mode".
%For fancy calligraphy letters, use \mathcal{}
%Special characters are their own commands

\subsection*{Problem 1: Regression Task}
We would like to perform regression task. We choose
$f(\cdot)=5(\cdot)^{+}=5ReLU(\cdot)$ and $g$ to be the identity function. To
train, we choose MSE loss function,
$\ell_{MSE}(\bm{\hat{y}},\bm{y})=||(\bm{\hat{y}}-\bm{y})||^2$.
\begin{enumerate}
  \item Name and mathematically describe the 5 programming steps you
        would take to train this model with PyTorch using SGD on a single batch
        of data.
        \begin{tcolorbox}
          \begin{enumerate}
            \item see vid 
          \end{enumerate}
        \end{tcolorbox}
  \item For a single data point $(x,y)$, write down all inputs and outputs for
        forward pass of each layer. You can only use variables and mechanics specified
        prior in your answer.
        \begin{tcolorbox}
          |$Linear_1$|\\ Input: $\bm{x}$\\Output ($z_1$): $\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}$\\
          |$f$|\\ Input: $Linear_1(\bm{x})=\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}$\\
          Output ($z_2$): $f(Linear_1(\bm{x}))=5ReLU(Linear_1(\bm{x}))\\
            =5ReLU(\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)})$\\
            $=5\max(0,\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)})$\\
          |$Linear_2$|\\ Input: $f(Linear_1(\bm{x}))$\\
          Output ($z_3$): $Linear_2(f(Linear_1(\bm{x})))=\bm{W}^{(2)}\bm{f(Linear_1(\bm{x}))}+\bm{b}^{(2)}$\\
          $=5\bm{W}^{(2)}((\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}))+\bm{b}^{(2)}$\\
          |g|\\Input: $Linear_2(f(Linear_1(\bm{x})))$\\
          Output: $g(Linear_2(f(Linear_1(\bm{x})))) = \\
          5(\bm{W}^{(2)}(\max(0,\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}))+\bm{b}^{(2)})\bm{I}$=\\
          $5(\bm{W}^{(2)}(\max(0,\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}))+\bm{b}^{(2)})=\bm{\hat{y}}$\\
          |Loss|\\
          Input: $\bm{\hat{y}}$\\
          Output: $(5(\bm{W}^{(2)}(\max(0,\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}))+\bm{b}^{(2)})-\bm{y})^2$\\
        \end{tcolorbox}
  \item Write down the gradients calculated from the backward pass. You can only use the following variables: $\bm{x,y,W^{(1)},b^{(1)},W^{(2)},b^{(2)}}, \frac{\partial \ell}{\partial \bm{\hat{y}}}, \frac{\partial \bm{z_2}}{\partial \bm{z_1}},\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}$, where $\bm{z_1,z_2,z_3,\hat{y}}$ are outputs of $Linear_1,f,Linear_2,g$, respectively.
        \begin{tcolorbox}
          \begin{flalign*}
            \frac{\partial \bm{z_3}}{\partial \bm{W^{(2)}}}&=\frac{\partial (5\bm{W^{(2)}\max(0,W^{(1)}x+b^{(1)})+b^{(2)}})}{\partial \bm{W^{(2)}}}\\
            &=5\bm{\max(0,W^{(1)}x+b^{(1)})}\\
            \frac{\partial \bm{z_3}}{\partial \bm{b^{(2)}}}&=\frac{\partial (5\bm{W^{(2)}\max(0,W^{(1)}x+b^{(1)})+b^{(2)}})}{\partial \bm{b^{(2)}}}\\
            &=1\\
            \frac{\partial \bm{\ell}}{\partial \bm{W^{(2)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{W^{(2)}}} \\
            &=5\frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\bm{\max(0,W^{(1)}x+b^{(1)})}\\
            \frac{\partial \bm{\ell}}{\partial \bm{b^{(2)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{b^{(2)}}} \\
            &=\frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\\
          \end{flalign*}
        \end{tcolorbox}
        \begin{tcolorbox}
          \begin{flalign*}
            \frac{\partial \bm{z_3}}{\partial \bm{z_2}}&=\frac{\partial (\bm{W^{(2)}}5\max(0,\bm{W^{(1)}x+b^{(1)}}))}{\partial 5 \max(0, \bm{W^{(1)}x+b^{(1)}})}=\bm{W^{(2)}}\\
            \frac{\partial \bm{z_1}}{\partial \bm{W^{(1)}}}&= \frac{\partial (\bm{W^{(1)}x+b^{(1)}})}{\bm{W^{(1)}}}=x\\
            \frac{\partial \bm{z_1}}{\partial \bm{b^{(1)}}}&= \frac{\partial (\bm{W^{(1)}x+b^{(1)}})}{\bm{b^{(1)}}}=1\\
           \frac{\partial \bm{\ell}}{\partial \bm{W^{(1)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{z_2}}\frac{\partial \bm{z_2}}{\partial \bm{z_1}}\frac{\partial \bm{z_1}}{\partial \bm{W^{(1)}}} \\
            &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\bm{W^{(2)}}\frac{\partial \bm{z_2}}{\partial \bm{z_1}}\bm{x}\\
            \frac{\partial \bm{\ell}}{\partial \bm{b^{(1)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{z_2}}\frac{\partial \bm{z_2}}{\partial \bm{z_1}}\frac{\partial \bm{z_1}}{\partial \bm{b^{(1)}}} \\
            &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\bm{W^{(2)}}\frac{\partial \bm{z_2}}{\partial \bm{z_1}}\\
          \end{flalign*}
        \end{tcolorbox}
  \item Show the elements of $\frac{\partial \bm{z_2}}{\partial \bm{z_1}}, \frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}},\frac{\partial \ell}{\partial \bm{\hat{y}}}$. Be careful about dimensionality.
        \begin{tcolorbox}
          Note: $ i \in \left\lbrace1,\ldots,m\right\rbrace$ used throughout.
          \begin{flalign*}
            \frac{\partial \bm{z_2}}{\partial \bm{z_1}} &= \frac{\partial  (5\max(0,\bm{W^{(1)}x+b^{(1)}}))}{\partial (\bm{W^{(1)}x+b^{(1)}})}\\
            \left( \frac{\partial \bm{z_2}}{\partial \bm{z_1}}  \right)_{ii} &= \begin{cases} 0, & z_{1i} < 0 \\ 5, & z_{1i} > 0 \\ \text{undefined (or assigned a value 0 in code)}, & z_{1i} = 0 \end{cases}\\
            \text{Note: } \bm{z_1} &= \bm{W^{(1)}x+b^{(1)}}\text{ and the above is a diagonal matrix} \\
            \left(\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}    \right)_{ii} &= 1 \text{ (and 0 elsewhere, off of diagonal; an identity matrix)}\\ 
            \frac{\partial \ell}{\partial \bm{\hat{y}}} &= \frac{\partial (||\bm{\hat{y}-y||^2})}{\partial \bm{\hat{y}}}=2\bm{{(\hat{y}-y)}^T} \text{ (A vector)}\\
          \end{flalign*}
        \end{tcolorbox}

\end{enumerate}

%If you want centered math on its own line, you can use a slash and square
%bracket.\\
%\[
%  \left \{
%  \sum\limits_{k=1}^\infty l(I_k):A\subseteq \bigcup_{k=1}^\infty \{I_k\}
%  \right \}
%\]
%The left and right commands make the brackets get as big as we need them to
%be.

\clearpage %Gives us a page break before the next section. Optional.
\subsection*{Problem 2: Classification Task}
We would like to perform multi-class classification task, so we set $f = tanh$ and $g = \sigma$, the logistic sigmoid function, $\sigma(z)=\frac{1}{1+\exp(-z)}$.
\begin{enumerate}
  \item If you want to train this network, what do you need to change in the equations of (1.2), (1.3) and (1.4), assuming we are using the same MSE loss function.
    \begin{tcolorbox}
      |$f$|\\ Input: $Linear_1(\bm{x})=\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}$\\
          Output ($z_2$): $f(Linear_1(\bm{x}))=\tanh(Linear_1(\bm{x}))\\
            =\tanh(\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)})$\\
            $=\frac{\exp(\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)})-\exp(-\bm{W}^{(1)}\bm{x}-\bm{b}^{(1)})}{\exp(\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)})+\exp(-\bm{W}^{(1)}\bm{x}-\bm{b}^{(1)})}$\\
          |$Linear_2$|\\ Input: $f(Linear_1(\bm{x}))=\tanh(Linear_1(x))$\\
          Output ($z_3$): $Linear_2(f(Linear_1(\bm{x})))=\bm{W}^{(2)}\bm{f(Linear_1(\bm{x}))}+\bm{b}^{(2)}$\\
          $=\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}}$\\
          |g|\\Input: $Linear_2(f(Linear_1(\bm{x})))$\\
          Output: $g(Linear_2(f(Linear_1(\bm{x})))) = \\
          \frac{1}{1+\exp(-f(Linear_1(\bm{x})))}=\frac{1}{1+\exp(-(\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}}))}=\bm{\hat{y}}$
    \end{tcolorbox}
    \begin{tcolorbox}
      \begin{flalign*}
        \frac{\partial \bm{z_3}}{\partial \bm{W^{(2)}}}&=\frac{\partial (\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}})}{\partial \bm{W^{(2)}}}\\
        &=\tanh(\bm{W^{(1)}x+b^{(1)}})\\
        \frac{\partial \bm{z_3}}{\partial \bm{b^{(2)}}}&=\frac{\partial (\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}})}{\partial \bm{b^{(2)}}}\\
        &=1\\
        \frac{\partial \bm{\ell}}{\partial \bm{W^{(2)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{W^{(2)}}} \\
        &=\frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\tanh(\bm{W^{(1)}x+b^{(1)}})\\
        \frac{\partial \bm{\ell}}{\partial \bm{b^{(2)}}} &= \frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\frac{\partial \bm{z_3}}{\partial \bm{b^{(2)}}} \\
        &=\frac{\partial \bm{\ell}}{\partial \bm{\hat{y}}}\frac{\partial \bm{\hat{y}}}{\partial \bm{z_3}}\\
      \end{flalign*}
    \end{tcolorbox}
    \begin{tcolorbox}
      \begin{flalign*}
        \frac{\partial \bm{z_3}}{\partial \bm{z_2}}&=\frac{\partial (\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}})}{\partial \tanh(\bm{W^{(1)}x+b^{(1)}})}=\bm{W^{(2)}}\\
        \frac{\partial \bm{z_2}}{\partial \bm{z_1}} &= \frac{\partial  (\tanh(\bm{W}^{(1)}\bm{x}+\bm{b}^{(1)}))}{\partial (\bm{W^{(1)}x+b^{(1)}})} = \frac{2}{\cosh(2(\bm{W^{(1)}x+b^{(1)}}))+1}\\
         &= 1-{\tanh(\bm{W^{(1)}x+b^{(1)}})}^2\\
         \frac{\partial \bm{\hat{y}}}{\partial z_3} &= \frac{\partial ({1+\exp(-(\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}}))})^{-1}}{\partial (\tanh(W^{(1)}x+b^{(1)})+b^{(2)})} \\
         &=\frac{{\exp(-(\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}}))}}{(1+\exp(-(\bm{W^{(2)}\tanh(W^{(1)}x+b^{(1)})+b^{(2)}})))^2}\\ 
      \end{flalign*}
    \end{tcolorbox}
\end{enumerate}

\subsection*{Problem 3}
%
\begin{proof}
  %
\end{proof}

\section*{Section 2.2}
%
\subsection*{Problem 6}
Blah
\subsection*{Problem 7}
Blah
\subsection*{Problem 10}
Blah

\end{document}